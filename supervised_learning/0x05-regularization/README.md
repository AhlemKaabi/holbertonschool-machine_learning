# **Regularization**

In mathematics, statistics, finance, computer science, particularly in machine learning and inverse problems, `regularization` is the process of adding information in order to solve an ill-posed problem or to prevent `overfitting`.

**Holberton School project - Machine learning Specialization**


## **Learning Objectives**
* What is *regularization*? What is its purpose?
#### Regularization Techniques
* What is are *L1* and *L2* *regularization*? What is the difference between the two methods?
* What is *dropout*?
* What is *early stopping*?
* What is *data augmentation*?
* How do you implement the above regularization methods in Numpy? Tensorflow?
* What are the pros and cons of the above regularization methods?

## **Blog - Regularization Techniques for Machine Learning models**

* check my blog on [Medium](https://ahlemkaabi1412.medium.com/regularization-techniques-for-machine-learning-models-6a3d179f2016) or check it as post in my [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:6894629035863793665/)


***Holberton School project - Machine learning Specialization***
